[System-Level Defense against Indirect Prompt Injection Attacks- AnInformation Flow Control Perspective](https://notebooklm.google.com/notebook/8e568be8-51c5-4ed9-9d18-41c340f55eee/audio)

[The Early Bird Catches the Leak- Unveiling Timing Side Channels in LLMServing Systems](https://notebooklm.google.com/notebook/c19d928d-601a-4303-a755-9d2fc77875ec/audio)

[Towards Novel Malicious Packet Recognition - A Few-Shot Learning Approach](https://notebooklm.google.com/notebook/76b3e8fd-fa0e-457b-8439-ae94b73681e0/audio)

[Adversarial Attacks to Multi-Modal Models](https://notebooklm.google.com/notebook/8d87208c-afed-4903-8573-f84b9c72a8d1/audio)

[An Adversarial Perspective on Machine Unlearning for AI Safety](https://notebooklm.google.com/notebook/d3ea8ea0-b7b3-4618-8884-e97ff15a824c/audio)

[Applying Pre-trained Multilingual BERT in Embeddings for Improved Malicious Prompt Injection Attacks Detection](https://notebooklm.google.com/notebook/d8fa4802-ea56-4b5f-88cd-63a1a2d117bf/audio)

[Attack Atlas- A Practitionerâ€™s Perspective on Challenges and Pitfalls in Red Teaming GenAI](https://notebooklm.google.com/notebook/c6821ae0-d33c-44cd-bfbc-36ea94973949/audio)

[Data Poisoning - Based Backdoor Attack Framework against Supervised Learning RulesofSpikingNeuralNetworks](https://notebooklm.google.com/notebook/b95ba433-0d57-47d6-9ca2-693a015176b1/audio)

[GenTel - Safe - A Unified Benchmark and Shielding Framework for Defending Against Prompt Injection Attacks](https://notebooklm.google.com/notebook/09c26540-a5ac-45ff-b67c-37bb05110269/audio)

[Hacking, The Lazy Way - LLM Augmented Pentesting](https://notebooklm.google.com/notebook/cc182594-5746-4aef-b1c4-7cbdb6293f81/audio)

[Holistic Automated Red Teaming for Large Language Models through Top-Down Test Case Generation and Multi-turn Interaction](https://notebooklm.google.com/notebook/70203ee7-faa0-4510-9dbe-ca6ee189dd39/audio)

[Jailbreaking Large Language Models with Symbolic Mathematics](https://notebooklm.google.com/notebook/911a34e7-eb61-4be1-adb1-416f50d0c90f/audio)

[LLM Honeypot- Leveraging Large Language Models as Advanced Interactive Honeypot Systems](https://notebooklm.google.com/notebook/c1cc2138-89f4-420d-8426-6fd4de954c8e/audio)

[Mitigating Backdoor Threats to Large Language Models - Advancement and Challenges](https://notebooklm.google.com/notebook/0c8597d1-8c4b-4bbe-b769-cfdd93235b51/audio)

[Mitigating Backdoor Threats to Large Language Models - Advancement and Challenges](https://notebooklm.google.com/notebook/587a136e-ccbf-4523-9eb6-f706aa13593a/audio)

[Model X-Ray - Detection of Hidden Malware in AI Model Weights using Few Shot Learning](https://notebooklm.google.com/notebook/d07de2d1-b9dc-4e08-9aee-23f671b5f5d7/audio)

[Multimodal Pragmatic Jailbreak on Text-to-image Models](https://notebooklm.google.com/notebook/4561fcf6-866a-41b0-959b-a932598297d0/audio)

[Prompt Obfuscation for Large Language Models](https://notebooklm.google.com/notebook/747b48c6-7985-400d-9771-b8d5601c93ef/audio)

[PROMPTFUZZ- Harnessing Fuzzing Techniques for Robust Testing of Prompt Injection in LLMs](https://notebooklm.google.com/notebook/3958b595-b058-42bb-96f2-1db23498c21d/audio)

[ROBUST LLM SAFEGUARDING VIA REFUSAL FEATURE ADVERSARIAL TRAINING](https://notebooklm.google.com/notebook/d7dd2190-b704-4557-b3a5-6f9c739fd0e2/audio)

[SECURING LARGE LANGUAGE MODELS- ADDRESSING BIAS, MISINFORMATION, AND PROMPT ATTACKS](https://notebooklm.google.com/notebook/dba050e0-b1b0-4cb1-ab8c-ed184aae7dcc/audio)